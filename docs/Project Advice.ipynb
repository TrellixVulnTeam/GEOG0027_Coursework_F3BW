{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Advice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These notes contain various additional pieces of advice about the Geog2021 coursework.\n",
    "\n",
    "These are formulated as a form of FAQ, in response to questions from students in previous years.\n",
    "\n",
    "If you have additional points you would like advice on or clarification of, please let the course tutor know, or post on the githid page.\n",
    "\n",
    "* [Selecting Landsat Scenes](Project%20Advice.ipynb#1-Selecting-Landsat-scenes)\n",
    "* [Range of years to use](Project%20Advice.ipynb#2-Range-of-years-to-use)\n",
    "* [Building a Mask](Project%20Advice.ipynb#3-Building-a-mask)\n",
    "* [Which Model to use?](Project%20Advice.ipynb#4-Which-Model-to-use)\n",
    "* [Data for modelling](Project%20Advice.ipynb#5-Data-for-Modelling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Selecting Landsat scenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "I've received a couple of questions about the Landsat scene selection for the project.\n",
    "\n",
    "First, I would like to stress that whilst this task is, in some ways, 'packaged', I have tried to make it (the task) and the issues that you will find in completing it as close to what you would likely find if you tried to do any monitoring of this sort with Landsat data (or other EO). \n",
    "\n",
    "So, discovering 'issues' that arise when looking for data is part of the learning process you need to go through. At the same time, if you are completely stumped on such issues, then I am happy to provide 'pointers' as to what you might consider.\n",
    "\n",
    "If you consider the project as stated as a typical research project, we have the main purpose of the exercise being to describe land cover (urban land use) change in this part of China as a function of socio-economic factors. Hopefully, if you read the papers on this, you will understand the context for wanting to know such things. As an empirical model, this is not going to directly provide you with the *causes* of urbanisation, but it will at least elucidate the strength of certain factors in describing it.\n",
    "\n",
    "To do the task, you need socio-economic data (for the model). I have only given you data for 1987 to 2000 inclusive (14 years)\n",
    "\n",
    "You will notice that you need to calculate *growth* in urban area, i.e. change, so with 14 values of urban area, you can get 13 values of change (or ... with 15 values, you can get 14 ...). This means that you need to concentrate your data acquisition on those years.\n",
    "\n",
    "Several students have told me that they cannot find appropriate datasets for some of the years. This is a useful observation, but one which you will encounter in reality (i.e. every time you do something of this sort), so you need to think through the options and do something appropriate. Remember, this is deliberately *not* set up as a recipe book for you ... we are trying to get to to learn how to do this sort of work, so expect to encounter problems and have to come up with possible solutions.\n",
    "\n",
    " \n",
    "\n",
    "As a starter on this topic though ... \n",
    "\n",
    "### (i) Data Gaps\n",
    "\n",
    "If you had gaps in your data for land cover, you could still run the model (and complete the practical), but in some cases, change would be calculated over several years (rather than per year). In that case, remember to take into account the varying gaps in the data when you calculate change per year (e.g. if you have data for 1996 and 2000, then clearly,\n",
    "\n",
    "change per year = [urban(2000)-urban(1996)]/(2000-1996)\n",
    "\n",
    "This is not an unreasonable approach to the problem, and if explained well (demonstrate that all data available for the missing years are of no value) would most likely be *sufficient*, but it has the problem that you will have fewer samples for your model (also harder to do any uncertainty analysis), and is really the 'easiest way out', so you are unlikely to get a 1st class mark for that. That said, you *could* choose to do this.\n",
    "\n",
    "*If there happened to be* a longer time series of socio-economic data available, then that would go some way towards mitigating the issues above, i.e. if we had socio-economic data for 1987-2010 for example, you would have greater choice of scenes, and this approach would be much more sensible as a piece of science.\n",
    "\n",
    "Another occasion when this might be a good option would be if the change between year X1 and and X2, even though spaced more than one year apart, showed little actual change (compared to that you see in the rest of the dataset). I am *not* saying that this is the case here, but if you found yourself in that situation, this simple approach would be quite justified.\n",
    "\n",
    " \n",
    "\n",
    "### (ii) time of year\n",
    "\n",
    "\n",
    "I have suggested that you initially limit your search for scenes to approximately the same time of year. You should be able to think through and discuss the reasons why that might be the 'best' thing to do. However, if it is not possible, you may have to relax those constraints (i.e. take datasets *not* at the same time of year).\n",
    "\n",
    "The *best* way to deal with that then might be to consider the series of all datasets as a sample of a continuous function of reflectance that relates to land cover (see e.g. W.B. Cohen, Y. Zhiqiang, R.E. Kenned, Detecting trends in forest disturbance and recovery using yearly Landsat time series: 2. TimeSync — Tools for calibration and validation, Remote Sensing of Environment, 114 (2010), pp. 2911–2924). This would mean that you could make use of any dataset that had a cloud-free *pixel* over the area of interest, which is rather a different proposition to simply looking for 'clear' scenes. This is probably the most appropriate method for the analysis of long-term datasets such as landsat, but as it would require tools and techniques you have not been introduced to, it is probably not feasible for you to do in this work. That said, you would still be best advised to make yourself aware of 'recent' trends in processing time series of landsat data that you might consider for the future.\n",
    "\n",
    "Assuming instead that you continue searching for only 'clear' scenes, and that you have to extend the range of months you look through, you might just consider this as an additional source of uncertainty on the inputs.\n",
    "\n",
    "### (iii) just use what you can and deal with 'holes'\n",
    "\n",
    "Another approach that could be reasonable is if you found a set of 'good', reasonably clear scenes that had some cloud cover over the area you are interest in, you could still do a classification on this and make use of the data in the model. The problem then would be that there are 'holes' in your dataset. There are several ways you could think of to get around this, e.g. make some assumption about the land cover in the 'holes' to fill out the area (e.g. its a weighted average of the last time you did get a view of the surface and the next time), or, if the holes were pretty much always in the same place, just mask that area out of all analyses.\n",
    "\n",
    " \n",
    "\n",
    "I think it would be reasonable to follow any of these routes. The 'full time series' approach of Cohen et al. is perhaps the most complex, and I am assuming this is probably out of scope for most, if not all of you (though if you wanted to have a go, I could provide further pointers ...). The simple basic approach (i) is ok, certainly as a first pass through the processing, but ultimately rather limited (particularly in the number of samples you have). So, you could try that first. Extending the months you look over is certainly an option to consider and perhaps try, but comes with its own issues. The 'dealing with holes' route is also worth thinking about.\n",
    "\n",
    "To re-iterate then, there are many viable options for dealing with this first issue you have been finding. There *is* a good solution (track all valid pixels from all scenes) but that takes you away somewhat from the techniques we have taught you and so is probably beyond the scope of this practical. There are several 'ok' solutions that you could try.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Range of years to use\n",
    "\n",
    "First, note that you do not need to go beyond the range of the years given to you in the socio-economic data spreadsheet (1987-2000).\n",
    "\n",
    "However, if you do want to explore further years, the following note from Dr Qingling Wu provides advice on this:\n",
    "\n",
    ">Links formatted like http://www.gdstats.gov.cn/tjnj/2008/ml_e.htm can be used for any year between 2006 and 2011 (inclusive). Since 2012, the yearbook became bilingual, and (like it was before) a number of key variables include data not only from one year but also from all previous years since 1978. The newest yearbook was made in 2014, and its data can be accessed from http://www.gdstats.gov.cn/tjnj/2014/directory.html. They even created an Excel download button at the top of each page: http://www.gdstats.gov.cn/tjnj/2014/directory/content.html?02-01.\n",
    "\n",
    "A small caveat: If you are considering using Landsat 7 data, you should first read about the issues with the sensor from 2003+ (http://landsat.usgs.gov/products_slcoffbackground.php). This does not mean that the data are unuseable, but it does mean you may need to find a work-around for the SLC-off issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Building a mask\n",
    "\n",
    "For the people who wanted to create a 'build a mask', you do not have to go through the process that has been outlined on the instruction sheet, instead you need do 'raster management' - 'masking' - 'Apply mask'. (rather than 'build a mask')."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Which Model to use\n",
    "\n",
    "In response to the following question from a student:\n",
    "\n",
    "> I’m currently working through the modelling of the classified areas. Comparing the model that is in the spreadsheet to the model given by Seto et al, there seems to be an additional coefficient (b4) in the spreadsheet model that is not found in Seto et al’s model.\n",
    " \n",
    "> I’m not fully sure what this coefficient does, and was wondering if you could explain it’s significance, as it seems to scale the productivity ratio, but the Seto equation does not require this.\n",
    "\n",
    "My response that you may find of value:\n",
    "\n",
    "> Hi - I'll check tomorrow, but from what I remember, the one you've got in the notes/spreadsheet is a combination of 2 models. So long as you put your data into at least one such model (it can be directly from seto or something similar like this) and obtain an estimate of the model parameters (the coefficients) then that is ok for a pass on that section. You can go further, eg trying /comparing a few different models if you wanted -- you might then need to think about how to compare models of different 'complexities' ( degrees of freedom here),but I'm not expecting you to know much about such things, but there are metrics of such things (information criteria, if you are interested, eg akaiki information criteria (AIC)).\n",
    " \n",
    "> In essence, if the goodness of fit of the model is 'pretty much the same' (it *will* go up, but 'same' here means it doesn't go up 'much', where 'much' can be defined in a statistical measure) when you get rid of one or more of the inputs (ie have a lower degree of freedom model), then that is a 'better' model.\n",
    " \n",
    "> One other thing you should consider in modelling is the uncertainty (or at least the relative uncertainty) on the independent (and dependent) variable -- change in area of urban (and the socio-economic inputs) might not all be equally accurate - your accuracy assessment of the classifications should come in handy in thinking about that. Also consider that the accuracy assessment you have done doesn't *directly* tell you the accuracy of *change* in urban area (although that can be estimated under certain assumptions).\n",
    " \n",
    "And further response wrt [2021_UrbanModel.ipynb](2021_UrbanModel.ipynb)\n",
    " \n",
    ">The models on the course web page (from Seto et al.) consider land cover change from:\n",
    " \n",
    ">natural to urban: a + b1 (inv/pop) + b2 log(wages) + b3 (relative ag output)   [eqn 1]\n",
    " \n",
    ">ag to urban:  a + b1 (ag output/pop) + b2 (invest/pop) + b3 log(wages) + b4 (relative ag output)  [eqn 2]\n",
    " \n",
    ">although the b4 is missing in the equation (or rather, assumed 1, for no apparent reason -- typo?)\n",
    " \n",
    ">The urban growth model you are given is:\n",
    " \n",
    ">change in urban area = a + b1 (invest/pop) + b2 (ag output/pop) + b3 log(private wages) + b4 log(total wages) + b5  (relative ag output)  [eqn 3]\n",
    " \n",
    ">The model spreadsheet is in [UrbanGrowthModel_Students.xlsx](https://github.com/profLewis/Geog2021_Coursework/blob/master/files/UrbanGrowthModel_Students.xlsx)\n",
    " \n",
    ">Columns E to L (8 columns) contains the data on e.g. investments, population etc.\n",
    "So, to get e.g. investments / population, you would need to divide the investments column by the population. You should be able to use the other data columns similarly to derive the dependent variables you need for the model.\n",
    " \n",
    ">You are expected to put in your own data for measured growth, and then to calculate the coefficients of the multi-linear regression model  [eqn 3 above] and assess the mismatch between model and data. \n",
    " \n",
    ">As noted above, you can also try to build a model with fewer coefficients and explore the issues around that, but that is not part of the core requirement. You could also e.g. build the natural to urban and agriculture to urban models separately if you like, but again that is not a core requirement. \n",
    " \n",
    ">Make sure that all choices you make (on what you do, what data you include, how you go about doing things) are clearly justified in the text (e.g. with an image & cloud stats of the 'best' cloudy scene for year X to illustrate a justification that there was no useful data for that year).\n",
    " \n",
    ">I hope this clarifies things.\n",
    ">Happy to respond to further questions.\n",
    " \n",
    ">ps -- don't forget to fill out the course feedback.\n",
    " \n",
    ">Lewis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Data for Modelling\n",
    "\n",
    "\n",
    "> I have been looking at the modelling of the classified areas.  I realise the formula is the urban growth formula from your notes.  However, when looking closely at the formula I understand that the log for the wages in private units(b3) and average total wages (b4) are not including in the formula.  Are these values already calculated to their logarithmic value or should we add this to the formula when applying our own data?\n",
    "\n",
    "Response:\n",
    " \n",
    ">The titles in the spreadsheet say e.g. 'average total wages (yuan)' ... since the formula ('model') you are using states the variable as log(average total wages), then you *should* apply a log transform.\n",
    " \n",
    "Another comment:\n",
    "\n",
    "> Also, I am a bit confused with the modelling with the parameters a b1 b2 b3 b4 b5 do we use trial and error to find the values that fit in our model or do we have to calculate these values?\n",
    " \n",
    "Response:\n",
    "\n",
    ">No -- you should not use trial and error. The equation is simply a multi-variate linear regression model. You are supposed to have learned how to solve for the parameters of that in your first year, which is why I give not explicit instructions here.\n",
    " \n",
    ">To better understand this, imagine that your model had only 1 input variable (e.g. population). In that case, the model would be:\n",
    " \n",
    ">`urban_change = a + b population`\n",
    "\n",
    ">and if you plotted urban_change as a function of population, this model would be assuming that there is s straight line describing this. In that case, you can interpret the 'parameter' a as the 'intercept' and the parameter 'b' as the slope (of the line). To estimate these from data, you would not guess the values, you would perform a linear regression. The same idea holds in this practical, but it is a multi-variate linear relationship.\n",
    " \n",
    ">I hope that helps\n",
    " \n",
    ">Lewis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
